---
title:          机器学习问答
date:           2020-09-10
author:         Echo
location:       Beijing 
tags: 
    - 面试
    - 机器学习
    - 数据挖掘
---


> Q1: 为什么交叉熵可用于代价计算（逻辑回归）？

为了让学习到的模型更贴近真实数据的分布，我们最小化**模型数据分布**与**训练数据分布**之间的 KL 散度，$KL(A||B) = - S(A) + H(A, B)$，而因为训练数据的分布是固定的，因此最小化 $KL(A||B)$ 等价于最小化交叉熵 $H(A, B)$。就逻辑回归而言，似然函数的最大化就是交叉熵的最小化。

> Q2：

