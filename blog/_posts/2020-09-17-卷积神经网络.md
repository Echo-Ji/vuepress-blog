---
title:          卷积神经网络
date:           2020-09-17
author:         Echo
location:       Beijing 
tags: 
    - 卷积
    - 神经网络
    - 深度学习
---

> 面试前整理的一些自己不熟悉的知识点，好想拥有一个硬盘一样的脑袋，可以不忘掉的那种。

## 卷积操作

### 卷积

卷积核也叫过滤器，根据是否使用 Padding 技术，可以分为 Same 卷积和 Valid 卷积。

* Valid 卷积：卷积后图像大小为 $(n - f + 1) \times (n - f + 1)$，其缺点是每次卷积，图像就会变小，第二个缺点是边缘像素的利用率较低。
* Same 卷积：Padding 之后卷积得到的图像大小为 $(n + 2p - f + 1) \times (n + 2p - f + 1)$，要使得卷积前后大小一致，即 $n + 2p - f + 1 = n$，则需要 $p = (f - 1) / 2$，通常采用 $f$ 为奇数的卷积核。

当选择步幅为 $s$ 时，输出图像的大小为 $\frac{n + 2p - f}{s} + 1$，为了保证其为整数，通常向下取整 $\lfloor \frac{n + 2p - f}{s} \rfloor + 1$，为了保证卷积核走出图像时不进行卷积操作。

### 2d/3d 卷积

* 2d 卷积里有单通道卷积核多通道卷积，其中多通道卷积中，各通道的权重可以有差异。
* 3d 卷积的卷积核在深度上不表现差异。注意区别多通道卷积和 3d 卷积。

## 卷积网络

卷积网络通常包含 3 个层：
* 卷积
* 池化：使用池化层来缩减模型的大小，提高计算速度，同时提高所提取特征的鲁棒性。池化会保持通道数不变，它拥有两个参数：大小 $f$ 和步长 $s$，通常采用最大池化，平均池化很少用。注意，池化层不需要学习，他是一个静态属性。
* 全连接

（为什么使用卷积网络？）相比于全连接网络，卷积网络的两个主要优势在于**权重共享**和**稀疏链接**。

卷积网络的发展：
* 经典网络LeNet-5 -> AlexNet -> VGG16
* ResNet(152)
* Inception

