---
title:          深度学习问答
date:           2020-09-12
author:         Echo
location:       Beijing 
tags: 
    - 面试
    - 深度学习
---

## Q1：如何调试超参数？

一般有两种方式：GridSearch 和 RandomSearch。

在选点个数一致的情况下，RandomSearch 会测试更多的超参数，比如对两个超参数选择 25 个点，对于第一个超参数 GridSearch 只能测试 5 个值，而 RandomSearch 也许可以测试 25 个值，这显然更高效，因此个人倾向于 RandomSearch。

## Q2：如何给超参数选择合适的范围？

不同的超参数选择方式不同，但一般分为两种：**线性随机选择**和**指数随机选择**。

**线性随机选择**就是在指定范围内线性生成随机数，写法如下

```Python
# 在 [a, b) 之间线性选择，比如网络层数范围为[2, 5)
para = np.random.rand() * (b - a) + a 
```

这种方式一般适用于神经网络的层数，每层的隐藏单元数等参数。

**指数随机选择**就是对指定范围求对数，然后生成随机数，再指数映射回去，写法如下

```Python
# 对范围 [10^a, 10^b) 取对数，比如学习率范围为 [0.001, 1)
a, b = np.log10(10^a), np.log10(10^b)
# 生成 [a, b) 之间的随机数
r = np.random.rand() * (b - a) + a
# 指数映射回去
para = 10 ^ r
```

这种方式一般适用于学习率，指数加权平均中 $1 - \beta$ 等参数。